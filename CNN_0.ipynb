{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "data_manager.py\n",
    "A file that loads saved features and convert them into PyTorch DataLoader.\n",
    "'''\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Class based on PyTorch Dataset\n",
    "class GTZANDataset(Dataset):\n",
    "\tdef __init__(self, x, y):\n",
    "\t\tself.x = x\n",
    "\t\tself.y = y\n",
    "\n",
    "\tdef __getitem__(self, index):\n",
    "\t\treturn self.x[index], self.y[index]\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn self.x.shape[0]\n",
    "\n",
    "# Function to get genre index for the given file\n",
    "def get_label(file_name, hparams):\n",
    "\tgenre = file_name.split('.')[0]\n",
    "\tlabel = hparams.genres.index(genre)\n",
    "\n",
    "\treturn label\n",
    "\n",
    "# Function for loading entire data from given dataset and return numpy array\n",
    "def load_dataset(set_name, hparams):\n",
    "\tx = []\n",
    "\ty = []\n",
    "\n",
    "\tdataset_path = os.path.join(hparams.feature_path, set_name)\n",
    "\tfor root, dirs, files in os.walk(dataset_path):\n",
    "\t\tfor file in files:\n",
    "\t\t\tdata = np.load(os.path.join(root, file))\n",
    "\t\t\tlabel = get_label(file, hparams)\n",
    "\t\t\tx.append(data)\n",
    "\t\t\ty.append(label)\n",
    "\n",
    "\tx = np.stack(x)\n",
    "\ty = np.stack(y)\n",
    "\n",
    "\treturn x, y\n",
    "\n",
    "# Function to load numpy data and normalize, it returns dataloader for train, valid, test\n",
    "def get_dataloader(hparams):\n",
    "\tx_train, y_train = load_dataset('train', hparams)\n",
    "\tx_valid, y_valid = load_dataset('valid', hparams)\n",
    "\tx_test, y_test = load_dataset('test', hparams)\n",
    "\n",
    "\tmean = np.mean(x_train)\n",
    "\tstd = np.std(x_train)\n",
    "\tx_train = (x_train - mean)/std\n",
    "\tx_valid = (x_valid - mean)/std\n",
    "\tx_test = (x_test - mean)/std\n",
    "\n",
    "\ttrain_set = GTZANDataset(x_train, y_train)\n",
    "\tvalid_set = GTZANDataset(x_valid, y_valid)\n",
    "\ttest_set = GTZANDataset(x_test, y_test)\n",
    "\n",
    "\ttrain_loader = DataLoader(train_set, batch_size=hparams.batch_size, shuffle=True, drop_last=False)\n",
    "\tvalid_loader = DataLoader(valid_set, batch_size=hparams.batch_size, shuffle=False, drop_last=False)\n",
    "\ttest_loader = DataLoader(test_set, batch_size=hparams.batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "\treturn train_loader, valid_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "data_manager.py\n",
    "A file that loads saved features and convert them into PyTorch DataLoader.\n",
    "'''\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Class based on PyTorch Dataset\n",
    "class GTZANDataset(Dataset):\n",
    "\tdef __init__(self, x, y):\n",
    "\t\tself.x = x\n",
    "\t\tself.y = y\n",
    "\n",
    "\tdef __getitem__(self, index):\n",
    "\t\treturn self.x[index], self.y[index]\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn self.x.shape[0]\n",
    "\n",
    "# Function to get genre index for the given file\n",
    "def get_label(file_name, hparams):\n",
    "\tgenre = file_name.split('.')[0]\n",
    "\tlabel = hparams.genres.index(genre)\n",
    "\n",
    "\treturn label\n",
    "\n",
    "# Function for loading entire data from given dataset and return numpy array\n",
    "def load_dataset(set_name, hparams):\n",
    "\tx = []\n",
    "\ty = []\n",
    "\n",
    "\tdataset_path = os.path.join(hparams.feature_path, set_name)\n",
    "\tfor root, dirs, files in os.walk(dataset_path):\n",
    "\t\tfor file in files:\n",
    "\t\t\tdata = np.load(os.path.join(root, file))\n",
    "\t\t\tlabel = get_label(file, hparams)\n",
    "\t\t\tx.append(data)\n",
    "\t\t\ty.append(label)\n",
    "\n",
    "\tx = np.stack(x)\n",
    "\ty = np.stack(y)\n",
    "\n",
    "\treturn x, y\n",
    "\n",
    "# Function to load numpy data and normalize, it returns dataloader for train, valid, test\n",
    "def get_dataloader(hparams):\n",
    "\tx_train, y_train = load_dataset('train', hparams)\n",
    "\tx_valid, y_valid = load_dataset('valid', hparams)\n",
    "\tx_test, y_test = load_dataset('test', hparams)\n",
    "\n",
    "\tmean = np.mean(x_train)\n",
    "\tstd = np.std(x_train)\n",
    "\tx_train = (x_train - mean)/std\n",
    "\tx_valid = (x_valid - mean)/std\n",
    "\tx_test = (x_test - mean)/std\n",
    "\n",
    "\ttrain_set = GTZANDataset(x_train, y_train)\n",
    "\tvalid_set = GTZANDataset(x_valid, y_valid)\n",
    "\ttest_set = GTZANDataset(x_test, y_test)\n",
    "\n",
    "\ttrain_loader = DataLoader(train_set, batch_size=hparams.batch_size, shuffle=True, drop_last=False)\n",
    "\tvalid_loader = DataLoader(valid_set, batch_size=hparams.batch_size, shuffle=False, drop_last=False)\n",
    "\ttest_loader = DataLoader(test_set, batch_size=hparams.batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "\treturn train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import argparse\n",
    "\n",
    "class HParams(object):\n",
    "\tdef __init__(self):\n",
    "\t\t# Dataset Settings\n",
    "\t\tself.dataset_path = './gtzan'\n",
    "\t\tself.feature_path = './feature'\n",
    "\t\tself.genres = ['classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae']\n",
    "\n",
    "\t\t# Feature Parameters\n",
    "\t\tself.sample_rate = 22050\n",
    "\t\tself.fft_size = 1024\n",
    "\t\tself.win_size = 1024\n",
    "\t\tself.hop_size = 512\n",
    "\t\tself.num_mels = 128\n",
    "\t\tself.feature_length = 1024  # audio length = feature_length*hop_size/sample_rate (s)\n",
    "\n",
    "\t\t# Training Parameters\n",
    "\t\tself.device = 1  # 0: CPU, 1: GPU0, 2: GPU1, ...\n",
    "\t\tself.batch_size = 10\n",
    "\t\tself.num_epochs = 200\n",
    "\t\tself.learning_rate = 1e-2\n",
    "\t\tself.stopping_rate = 1e-10\n",
    "\t\tself.weight_decay = 1e-6\n",
    "\t\tself.momentum = 0.9\n",
    "\t\tself.factor = 0.2\n",
    "\t\tself.patience = 3.\n",
    "\n",
    "\t# Function for parsing argument and set hyper parameters\n",
    "# \tdef parse_argument(self, print_argument=True):\n",
    "# \t\tparser = argparse.ArgumentParser()\n",
    "# \t\tfor var in vars(self):\n",
    "# \t\t\tvalue = getattr(hparams, var)\n",
    "# \t\t\targument = '--' + var\n",
    "# \t\t\tparser.add_argument(argument, type=type(value), default=value)\n",
    "\n",
    "# \t\targs = parser.parse_args()\n",
    "# \t\tfor var in vars(self):\n",
    "# \t\t\tsetattr(hparams, var, getattr(args, var))\n",
    "\n",
    "# \t\tif print_argument:\n",
    "# \t\t\tprint('-------------------------')\n",
    "# \t\t\tprint('Hyper Parameter Settings')\n",
    "# \t\t\tprint('-------------------------')\n",
    "# \t\t\tfor var in vars(self):\n",
    "# \t\t\t\tvalue = getattr(hparams, var)\n",
    "# \t\t\t\tprint(var + ': ' + str(value))\n",
    "# \t\t\tprint('-------------------------')\n",
    "\n",
    "hparams = HParams()\n",
    "# hparams.parse_argument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model_archive.py\n",
    "A file that contains neural network models.\n",
    "You can also implement your own model here.\n",
    "'''\n",
    "import torch.nn as nn\n",
    "\n",
    "class Baseline(nn.Module):\n",
    "    def __init__(self, hparams):\n",
    "        super(Baseline, self).__init__()\n",
    "        \n",
    "        \n",
    "        # 128,32 kernel 8, strid 1 \n",
    "        self.conv0 = nn.Sequential(\n",
    "        nn.Conv1d(hparams.num_mels, 64, kernel_size=8, stride=1, padding=1),\n",
    "        nn.BatchNorm1d(64),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool1d(4, stride=4)\n",
    "        )\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "        nn.Conv1d(64, 128, kernel_size=4, stride=1, padding=1),\n",
    "        nn.BatchNorm1d(128),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool1d(3, stride=3)\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "        nn.Conv1d(128, 256, kernel_size=8, stride=1, padding=1),\n",
    "        nn.BatchNorm1d(256),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool1d(4, stride=4)\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "        nn.Conv1d(256, 512, kernel_size=4, stride=1, padding=1),\n",
    "        nn.BatchNorm1d(512),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool1d(4, stride=4)\n",
    "        )\n",
    "        \n",
    "        self.conv4 = nn.Sequential(\n",
    "        nn.Conv1d(512, 64, kernel_size=4, stride=1, padding=1),\n",
    "        nn.BatchNorm1d(64),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool1d(4, stride=4)\n",
    "        )\n",
    "        \n",
    "\n",
    "        self.linear0 = nn.Linear(64, 96)\n",
    "        self.linear3 = nn.Linear(96, len(hparams.genres))\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        x = x.transpose(1, 2)\n",
    "        #print(x.shape)\n",
    "        x = self.conv0(x)\n",
    "        #print(x.shape)\n",
    "        x = self.conv1(x)\n",
    "        #print(x.shape)\n",
    "        x = self.conv2(x)\n",
    "        #print(x.shape)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        #print(x.shape)\n",
    "        x = x.view(x.size(0), x.size(1)*x.size(2))\n",
    "        #print(x.shape)\n",
    "        x = self.linear0(x)\n",
    "        x = self.linear3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv0 = nn.Sequential(\n",
    "        nn.Conv1d(hparams.num_mels, 32, kernel_size=8, stride=1, padding=0),\n",
    "        nn.BatchNorm1d(32),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool1d(8, stride=8)\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7401"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__\n",
    "torch.backends.cudnn.version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "train_test.py\n",
    "A file for training model for genre classification.\n",
    "Please check the device in hparams.py before you run this code.\n",
    "'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# import data_manager\n",
    "# import models\n",
    "# from hparams import hparams\n",
    "\n",
    "# Wrapper class to run PyTorch model\n",
    "class Runner(object):\n",
    "    def __init__(self, hparams):\n",
    "        self.model = Baseline(hparams)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        #Adam Optimizer 사용\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=hparams.learning_rate)\n",
    "        #self.optimizer = torch.optim.SGD(self.model.parameters(), lr=hparams.learning_rate, momentum=hparams.momentum)\n",
    "        self.scheduler = ReduceLROnPlateau(self.optimizer, mode='min', factor=hparams.factor, patience=hparams.patience, verbose=True)\n",
    "        self.learning_rate = hparams.learning_rate\n",
    "        self.stopping_rate = hparams.stopping_rate\n",
    "        self.device = torch.device(\"cpu\")\n",
    "\n",
    "        if hparams.device > 0:\n",
    "            torch.cuda.set_device(hparams.device - 1)##\n",
    "            self.model.cuda(hparams.device - 1)\n",
    "            self.criterion.cuda(hparams.device - 1)\n",
    "            self.device = torch.device(\"cuda:\" + str(hparams.device - 1))\n",
    "            \n",
    "#         device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "#         self.model = Baseline(hparams).to(device)\n",
    "#         if torch.cuda.device_count() > 1:\n",
    "#             print('\\n===> Training on GPU!')\n",
    "#             self.model = nn.DataParallel(net)\n",
    "\n",
    "    # Accuracy function works like loss function in PyTorch\n",
    "    def accuracy(self, source, target):\n",
    "        source = source.max(1)[1].long().cpu()\n",
    "        target = target.cpu()\n",
    "        correct = (source == target).sum().item()\n",
    "\n",
    "        return correct/float(source.size(0))\n",
    "\n",
    "    # Running model for train, test and validation. mode: 'train' for training, 'eval' for validation and test\n",
    "    def run(self, dataloader, mode='train'):\n",
    "        self.model.train() if mode is 'train' else self.model.eval()\n",
    "\n",
    "        epoch_loss = 0.0\n",
    "        epoch_acc = 0.0\n",
    "        \n",
    "        for batch, (x, y) in enumerate(dataloader):\n",
    "            x = x.to(self.device)\n",
    "            y = y.to(self.device).type(torch.long)\n",
    "            \n",
    "            #print(y)\n",
    "\n",
    "            prediction = self.model(x)\n",
    "            loss = self.criterion(prediction, y)\n",
    "            acc = self.accuracy(prediction, y)\n",
    "\n",
    "            if mode is 'train':\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "            epoch_loss += prediction.size(0)*loss.item()\n",
    "            epoch_acc += prediction.size(0)*acc\n",
    "\n",
    "        epoch_loss = epoch_loss/len(dataloader.dataset)\n",
    "        epoch_acc = epoch_acc/len(dataloader.dataset)\n",
    "\n",
    "        return epoch_loss, epoch_acc\n",
    "\n",
    "    # Early stopping function for given validation loss\n",
    "    def early_stop(self, loss, epoch):\n",
    "        self.scheduler.step(loss, epoch)\n",
    "        self.learning_rate = self.optimizer.param_groups[0]['lr']\n",
    "        stop = self.learning_rate < self.stopping_rate\n",
    "\n",
    "        return stop\n",
    "\n",
    "def device_name(device):\n",
    "    if device == 0:\n",
    "        device_name = 'CPU'\n",
    "    else:\n",
    "        device_name = 'GPU:' + str(device - 1)\n",
    "\n",
    "    return device_name\n",
    "\n",
    "def main():\n",
    "    train_loader, valid_loader, test_loader = get_dataloader(hparams)\n",
    "    runner = Runner(hparams)\n",
    "\n",
    "    print('Training on ' + device_name(hparams.device))\n",
    "    for epoch in range(hparams.num_epochs):\n",
    "        train_loss, train_acc = runner.run(train_loader, 'train')\n",
    "        valid_loss, valid_acc = runner.run(valid_loader, 'eval')\n",
    "\n",
    "        print(\"[Epoch %d/%d] [Train Loss: %.4f] [Train Acc: %.4f] [Valid Loss: %.4f] [Valid Acc: %.4f]\" %\n",
    "              (epoch + 1, hparams.num_epochs, train_loss, train_acc, valid_loss, valid_acc))\n",
    "\n",
    "        if runner.early_stop(valid_loss, epoch + 1):\n",
    "            break\n",
    "\n",
    "    test_loss, test_acc = runner.run(test_loader, 'eval')\n",
    "    print(\"Training Finished\")\n",
    "    print(\"Test Accuracy: %.2f%%\" % (100*test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU:0\n",
      "[Epoch 1/200] [Train Loss: 1.9742] [Train Acc: 0.2096] [Valid Loss: 2.2881] [Valid Acc: 0.3067]\n",
      "[Epoch 2/200] [Train Loss: 1.7268] [Train Acc: 0.3201] [Valid Loss: 1.9844] [Valid Acc: 0.1933]\n",
      "[Epoch 3/200] [Train Loss: 1.6361] [Train Acc: 0.3428] [Valid Loss: 1.5047] [Valid Acc: 0.3933]\n",
      "[Epoch 4/200] [Train Loss: 1.4850] [Train Acc: 0.4873] [Valid Loss: 2.1161] [Valid Acc: 0.3867]\n",
      "[Epoch 5/200] [Train Loss: 1.5019] [Train Acc: 0.4306] [Valid Loss: 1.4650] [Valid Acc: 0.5200]\n",
      "[Epoch 6/200] [Train Loss: 1.3466] [Train Acc: 0.5127] [Valid Loss: 1.6637] [Valid Acc: 0.4200]\n",
      "[Epoch 7/200] [Train Loss: 1.3034] [Train Acc: 0.5297] [Valid Loss: 2.0092] [Valid Acc: 0.4267]\n",
      "[Epoch 8/200] [Train Loss: 1.2625] [Train Acc: 0.5269] [Valid Loss: 1.5617] [Valid Acc: 0.4333]\n",
      "[Epoch 9/200] [Train Loss: 1.1928] [Train Acc: 0.5892] [Valid Loss: 2.0687] [Valid Acc: 0.4067]\n",
      "Epoch     9: reducing learning rate of group 0 to 2.0000e-03.\n",
      "[Epoch 10/200] [Train Loss: 1.0686] [Train Acc: 0.6346] [Valid Loss: 1.4452] [Valid Acc: 0.4733]\n",
      "[Epoch 11/200] [Train Loss: 0.9799] [Train Acc: 0.6062] [Valid Loss: 1.2945] [Valid Acc: 0.5200]\n",
      "[Epoch 12/200] [Train Loss: 0.8578] [Train Acc: 0.6856] [Valid Loss: 1.2883] [Valid Acc: 0.5400]\n",
      "[Epoch 13/200] [Train Loss: 0.8198] [Train Acc: 0.6912] [Valid Loss: 1.4020] [Valid Acc: 0.4867]\n",
      "[Epoch 14/200] [Train Loss: 0.8199] [Train Acc: 0.6941] [Valid Loss: 1.3737] [Valid Acc: 0.5267]\n",
      "[Epoch 15/200] [Train Loss: 0.8365] [Train Acc: 0.6969] [Valid Loss: 1.3494] [Valid Acc: 0.5600]\n",
      "[Epoch 16/200] [Train Loss: 0.7645] [Train Acc: 0.6997] [Valid Loss: 1.5068] [Valid Acc: 0.4467]\n",
      "Epoch    16: reducing learning rate of group 0 to 4.0000e-04.\n",
      "[Epoch 17/200] [Train Loss: 0.7201] [Train Acc: 0.7337] [Valid Loss: 1.3244] [Valid Acc: 0.5067]\n",
      "[Epoch 18/200] [Train Loss: 0.7662] [Train Acc: 0.7224] [Valid Loss: 1.3012] [Valid Acc: 0.5333]\n",
      "[Epoch 19/200] [Train Loss: 0.7124] [Train Acc: 0.7705] [Valid Loss: 1.4655] [Valid Acc: 0.4800]\n",
      "[Epoch 20/200] [Train Loss: 0.7573] [Train Acc: 0.7337] [Valid Loss: 1.4045] [Valid Acc: 0.5133]\n",
      "Epoch    20: reducing learning rate of group 0 to 8.0000e-05.\n",
      "[Epoch 21/200] [Train Loss: 0.6352] [Train Acc: 0.7847] [Valid Loss: 1.3165] [Valid Acc: 0.5600]\n",
      "[Epoch 22/200] [Train Loss: 0.6405] [Train Acc: 0.7819] [Valid Loss: 1.2922] [Valid Acc: 0.5667]\n",
      "[Epoch 23/200] [Train Loss: 0.6385] [Train Acc: 0.7394] [Valid Loss: 1.3156] [Valid Acc: 0.5667]\n",
      "[Epoch 24/200] [Train Loss: 0.6657] [Train Acc: 0.7819] [Valid Loss: 1.3653] [Valid Acc: 0.5400]\n",
      "Epoch    24: reducing learning rate of group 0 to 1.6000e-05.\n",
      "[Epoch 25/200] [Train Loss: 0.6152] [Train Acc: 0.7875] [Valid Loss: 1.3753] [Valid Acc: 0.5600]\n",
      "[Epoch 26/200] [Train Loss: 0.6924] [Train Acc: 0.7535] [Valid Loss: 1.3098] [Valid Acc: 0.5467]\n",
      "[Epoch 27/200] [Train Loss: 0.6914] [Train Acc: 0.7507] [Valid Loss: 1.2678] [Valid Acc: 0.5733]\n",
      "[Epoch 28/200] [Train Loss: 0.6032] [Train Acc: 0.7932] [Valid Loss: 1.2851] [Valid Acc: 0.5667]\n",
      "[Epoch 29/200] [Train Loss: 0.5761] [Train Acc: 0.8074] [Valid Loss: 1.2755] [Valid Acc: 0.5600]\n",
      "[Epoch 30/200] [Train Loss: 0.6058] [Train Acc: 0.7734] [Valid Loss: 1.2941] [Valid Acc: 0.5667]\n",
      "[Epoch 31/200] [Train Loss: 0.6112] [Train Acc: 0.7649] [Valid Loss: 1.3309] [Valid Acc: 0.5267]\n",
      "Epoch    31: reducing learning rate of group 0 to 3.2000e-06.\n",
      "[Epoch 32/200] [Train Loss: 0.6118] [Train Acc: 0.7904] [Valid Loss: 1.2871] [Valid Acc: 0.5600]\n",
      "[Epoch 33/200] [Train Loss: 0.6051] [Train Acc: 0.7960] [Valid Loss: 1.2845] [Valid Acc: 0.5600]\n",
      "[Epoch 34/200] [Train Loss: 0.5784] [Train Acc: 0.7960] [Valid Loss: 1.3297] [Valid Acc: 0.5733]\n",
      "[Epoch 35/200] [Train Loss: 0.6360] [Train Acc: 0.7535] [Valid Loss: 1.3629] [Valid Acc: 0.5400]\n",
      "Epoch    35: reducing learning rate of group 0 to 6.4000e-07.\n",
      "[Epoch 36/200] [Train Loss: 0.6477] [Train Acc: 0.7564] [Valid Loss: 1.2931] [Valid Acc: 0.5800]\n",
      "[Epoch 37/200] [Train Loss: 0.6474] [Train Acc: 0.7819] [Valid Loss: 1.3590] [Valid Acc: 0.5267]\n",
      "[Epoch 38/200] [Train Loss: 0.6548] [Train Acc: 0.7479] [Valid Loss: 1.3510] [Valid Acc: 0.5467]\n",
      "[Epoch 39/200] [Train Loss: 0.6343] [Train Acc: 0.7507] [Valid Loss: 1.2902] [Valid Acc: 0.5467]\n",
      "Epoch    39: reducing learning rate of group 0 to 1.2800e-07.\n",
      "[Epoch 40/200] [Train Loss: 0.6102] [Train Acc: 0.7989] [Valid Loss: 1.2995] [Valid Acc: 0.5533]\n",
      "[Epoch 41/200] [Train Loss: 0.6301] [Train Acc: 0.7564] [Valid Loss: 1.2850] [Valid Acc: 0.5400]\n",
      "[Epoch 42/200] [Train Loss: 0.6289] [Train Acc: 0.7960] [Valid Loss: 1.2688] [Valid Acc: 0.5667]\n",
      "[Epoch 43/200] [Train Loss: 0.6534] [Train Acc: 0.7677] [Valid Loss: 1.2925] [Valid Acc: 0.5600]\n",
      "Epoch    43: reducing learning rate of group 0 to 2.5600e-08.\n",
      "[Epoch 44/200] [Train Loss: 0.6113] [Train Acc: 0.7989] [Valid Loss: 1.2673] [Valid Acc: 0.5733]\n",
      "[Epoch 45/200] [Train Loss: 0.6012] [Train Acc: 0.7819] [Valid Loss: 1.2925] [Valid Acc: 0.5533]\n",
      "[Epoch 46/200] [Train Loss: 0.6294] [Train Acc: 0.7677] [Valid Loss: 1.3835] [Valid Acc: 0.4933]\n",
      "[Epoch 47/200] [Train Loss: 0.6257] [Train Acc: 0.7989] [Valid Loss: 1.3155] [Valid Acc: 0.5533]\n",
      "[Epoch 48/200] [Train Loss: 0.6558] [Train Acc: 0.7422] [Valid Loss: 1.4695] [Valid Acc: 0.5000]\n",
      "Epoch    48: reducing learning rate of group 0 to 5.1200e-09.\n",
      "[Epoch 49/200] [Train Loss: 0.6143] [Train Acc: 0.7762] [Valid Loss: 1.2586] [Valid Acc: 0.5600]\n",
      "[Epoch 50/200] [Train Loss: 0.6016] [Train Acc: 0.8017] [Valid Loss: 1.3160] [Valid Acc: 0.5467]\n",
      "[Epoch 51/200] [Train Loss: 0.6355] [Train Acc: 0.7790] [Valid Loss: 1.3139] [Valid Acc: 0.5667]\n",
      "[Epoch 52/200] [Train Loss: 0.5884] [Train Acc: 0.7734] [Valid Loss: 1.2495] [Valid Acc: 0.5733]\n",
      "[Epoch 53/200] [Train Loss: 0.5676] [Train Acc: 0.7960] [Valid Loss: 1.3348] [Valid Acc: 0.5600]\n",
      "[Epoch 54/200] [Train Loss: 0.6165] [Train Acc: 0.7790] [Valid Loss: 1.4086] [Valid Acc: 0.5000]\n",
      "[Epoch 55/200] [Train Loss: 0.5869] [Train Acc: 0.7904] [Valid Loss: 1.3821] [Valid Acc: 0.5267]\n",
      "[Epoch 56/200] [Train Loss: 0.5942] [Train Acc: 0.7904] [Valid Loss: 1.4134] [Valid Acc: 0.5600]\n",
      "[Epoch 57/200] [Train Loss: 0.6840] [Train Acc: 0.7450] [Valid Loss: 1.2984] [Valid Acc: 0.5733]\n",
      "[Epoch 58/200] [Train Loss: 0.6365] [Train Acc: 0.7819] [Valid Loss: 1.3283] [Valid Acc: 0.5400]\n",
      "[Epoch 59/200] [Train Loss: 0.6836] [Train Acc: 0.7705] [Valid Loss: 1.3711] [Valid Acc: 0.5333]\n",
      "[Epoch 60/200] [Train Loss: 0.5817] [Train Acc: 0.7705] [Valid Loss: 1.3248] [Valid Acc: 0.5600]\n",
      "[Epoch 61/200] [Train Loss: 0.5793] [Train Acc: 0.8045] [Valid Loss: 1.3739] [Valid Acc: 0.5333]\n",
      "[Epoch 62/200] [Train Loss: 0.6113] [Train Acc: 0.7790] [Valid Loss: 1.3486] [Valid Acc: 0.5467]\n",
      "[Epoch 63/200] [Train Loss: 0.5693] [Train Acc: 0.7819] [Valid Loss: 1.3290] [Valid Acc: 0.5667]\n",
      "[Epoch 64/200] [Train Loss: 0.5894] [Train Acc: 0.7819] [Valid Loss: 1.3593] [Valid Acc: 0.5133]\n",
      "[Epoch 65/200] [Train Loss: 0.6782] [Train Acc: 0.7620] [Valid Loss: 1.3065] [Valid Acc: 0.5733]\n",
      "[Epoch 66/200] [Train Loss: 0.5991] [Train Acc: 0.7819] [Valid Loss: 1.3888] [Valid Acc: 0.5200]\n",
      "[Epoch 67/200] [Train Loss: 0.6163] [Train Acc: 0.7734] [Valid Loss: 1.3390] [Valid Acc: 0.5133]\n",
      "[Epoch 68/200] [Train Loss: 0.6234] [Train Acc: 0.7762] [Valid Loss: 1.3632] [Valid Acc: 0.5067]\n",
      "[Epoch 69/200] [Train Loss: 0.6366] [Train Acc: 0.7734] [Valid Loss: 1.3475] [Valid Acc: 0.5200]\n",
      "[Epoch 70/200] [Train Loss: 0.5440] [Train Acc: 0.8329] [Valid Loss: 1.2994] [Valid Acc: 0.5400]\n",
      "[Epoch 71/200] [Train Loss: 0.6538] [Train Acc: 0.7705] [Valid Loss: 1.3449] [Valid Acc: 0.5533]\n",
      "[Epoch 72/200] [Train Loss: 0.5936] [Train Acc: 0.7564] [Valid Loss: 1.3576] [Valid Acc: 0.5867]\n",
      "[Epoch 73/200] [Train Loss: 0.6998] [Train Acc: 0.7620] [Valid Loss: 1.3004] [Valid Acc: 0.5533]\n",
      "[Epoch 74/200] [Train Loss: 0.5710] [Train Acc: 0.7875] [Valid Loss: 1.2996] [Valid Acc: 0.5600]\n",
      "[Epoch 75/200] [Train Loss: 0.6408] [Train Acc: 0.7564] [Valid Loss: 1.3385] [Valid Acc: 0.5400]\n",
      "[Epoch 76/200] [Train Loss: 0.6570] [Train Acc: 0.7677] [Valid Loss: 1.3938] [Valid Acc: 0.4867]\n",
      "[Epoch 77/200] [Train Loss: 0.5673] [Train Acc: 0.7932] [Valid Loss: 1.2922] [Valid Acc: 0.5600]\n",
      "[Epoch 78/200] [Train Loss: 0.5762] [Train Acc: 0.8074] [Valid Loss: 1.3169] [Valid Acc: 0.5467]\n",
      "[Epoch 79/200] [Train Loss: 0.5967] [Train Acc: 0.7819] [Valid Loss: 1.2689] [Valid Acc: 0.5733]\n",
      "[Epoch 80/200] [Train Loss: 0.6571] [Train Acc: 0.7705] [Valid Loss: 1.3135] [Valid Acc: 0.5333]\n",
      "[Epoch 81/200] [Train Loss: 0.6371] [Train Acc: 0.7479] [Valid Loss: 1.2701] [Valid Acc: 0.5600]\n",
      "[Epoch 82/200] [Train Loss: 0.5839] [Train Acc: 0.7705] [Valid Loss: 1.3115] [Valid Acc: 0.5333]\n",
      "[Epoch 83/200] [Train Loss: 0.6446] [Train Acc: 0.7790] [Valid Loss: 1.3652] [Valid Acc: 0.5333]\n",
      "[Epoch 84/200] [Train Loss: 0.7409] [Train Acc: 0.7167] [Valid Loss: 1.3175] [Valid Acc: 0.5667]\n",
      "[Epoch 85/200] [Train Loss: 0.6896] [Train Acc: 0.7252] [Valid Loss: 1.2517] [Valid Acc: 0.5467]\n",
      "[Epoch 86/200] [Train Loss: 0.5956] [Train Acc: 0.7875] [Valid Loss: 1.2720] [Valid Acc: 0.5600]\n",
      "[Epoch 87/200] [Train Loss: 0.5992] [Train Acc: 0.7989] [Valid Loss: 1.2395] [Valid Acc: 0.5800]\n",
      "[Epoch 88/200] [Train Loss: 0.6023] [Train Acc: 0.7507] [Valid Loss: 1.3478] [Valid Acc: 0.5333]\n",
      "[Epoch 89/200] [Train Loss: 0.6723] [Train Acc: 0.7564] [Valid Loss: 1.3300] [Valid Acc: 0.5267]\n",
      "[Epoch 90/200] [Train Loss: 0.6035] [Train Acc: 0.7819] [Valid Loss: 1.3428] [Valid Acc: 0.6067]\n",
      "[Epoch 91/200] [Train Loss: 0.7341] [Train Acc: 0.7139] [Valid Loss: 1.3165] [Valid Acc: 0.5667]\n",
      "[Epoch 92/200] [Train Loss: 0.6513] [Train Acc: 0.7677] [Valid Loss: 1.2964] [Valid Acc: 0.5400]\n",
      "[Epoch 93/200] [Train Loss: 0.5691] [Train Acc: 0.8159] [Valid Loss: 1.3361] [Valid Acc: 0.5667]\n",
      "[Epoch 94/200] [Train Loss: 0.5975] [Train Acc: 0.7734] [Valid Loss: 1.2728] [Valid Acc: 0.5467]\n",
      "[Epoch 95/200] [Train Loss: 0.6574] [Train Acc: 0.7790] [Valid Loss: 1.2978] [Valid Acc: 0.5600]\n",
      "[Epoch 96/200] [Train Loss: 0.6189] [Train Acc: 0.7762] [Valid Loss: 1.2916] [Valid Acc: 0.5533]\n",
      "[Epoch 97/200] [Train Loss: 0.6486] [Train Acc: 0.7564] [Valid Loss: 1.2469] [Valid Acc: 0.5867]\n",
      "[Epoch 98/200] [Train Loss: 0.6524] [Train Acc: 0.7592] [Valid Loss: 1.3569] [Valid Acc: 0.5133]\n",
      "[Epoch 99/200] [Train Loss: 0.6431] [Train Acc: 0.7479] [Valid Loss: 1.2724] [Valid Acc: 0.5733]\n",
      "[Epoch 100/200] [Train Loss: 0.6581] [Train Acc: 0.7847] [Valid Loss: 1.3716] [Valid Acc: 0.5133]\n",
      "[Epoch 101/200] [Train Loss: 0.5768] [Train Acc: 0.8045] [Valid Loss: 1.3707] [Valid Acc: 0.5333]\n",
      "[Epoch 102/200] [Train Loss: 0.6374] [Train Acc: 0.7620] [Valid Loss: 1.3203] [Valid Acc: 0.5667]\n",
      "[Epoch 103/200] [Train Loss: 0.6167] [Train Acc: 0.8159] [Valid Loss: 1.3299] [Valid Acc: 0.5400]\n",
      "[Epoch 104/200] [Train Loss: 0.6759] [Train Acc: 0.7677] [Valid Loss: 1.3376] [Valid Acc: 0.5467]\n",
      "[Epoch 105/200] [Train Loss: 0.6313] [Train Acc: 0.7734] [Valid Loss: 1.3396] [Valid Acc: 0.5333]\n",
      "[Epoch 106/200] [Train Loss: 0.6115] [Train Acc: 0.7592] [Valid Loss: 1.2682] [Valid Acc: 0.5600]\n",
      "[Epoch 107/200] [Train Loss: 0.6393] [Train Acc: 0.7620] [Valid Loss: 1.2765] [Valid Acc: 0.5800]\n",
      "[Epoch 108/200] [Train Loss: 0.6682] [Train Acc: 0.7620] [Valid Loss: 1.4026] [Valid Acc: 0.5600]\n",
      "[Epoch 109/200] [Train Loss: 0.5415] [Train Acc: 0.8159] [Valid Loss: 1.3916] [Valid Acc: 0.5067]\n",
      "[Epoch 110/200] [Train Loss: 0.6432] [Train Acc: 0.7790] [Valid Loss: 1.3230] [Valid Acc: 0.5400]\n",
      "[Epoch 111/200] [Train Loss: 0.6521] [Train Acc: 0.7592] [Valid Loss: 1.3307] [Valid Acc: 0.5467]\n",
      "[Epoch 112/200] [Train Loss: 0.5748] [Train Acc: 0.7677] [Valid Loss: 1.3338] [Valid Acc: 0.5333]\n",
      "[Epoch 113/200] [Train Loss: 0.6019] [Train Acc: 0.7932] [Valid Loss: 1.2930] [Valid Acc: 0.5400]\n",
      "[Epoch 114/200] [Train Loss: 0.5940] [Train Acc: 0.7592] [Valid Loss: 1.3902] [Valid Acc: 0.5400]\n",
      "[Epoch 115/200] [Train Loss: 0.6943] [Train Acc: 0.7450] [Valid Loss: 1.3177] [Valid Acc: 0.5533]\n",
      "[Epoch 116/200] [Train Loss: 0.5769] [Train Acc: 0.7847] [Valid Loss: 1.3724] [Valid Acc: 0.5133]\n",
      "[Epoch 117/200] [Train Loss: 0.5543] [Train Acc: 0.8045] [Valid Loss: 1.3501] [Valid Acc: 0.5533]\n",
      "[Epoch 118/200] [Train Loss: 0.6157] [Train Acc: 0.7847] [Valid Loss: 1.3457] [Valid Acc: 0.5333]\n",
      "[Epoch 119/200] [Train Loss: 0.6162] [Train Acc: 0.7592] [Valid Loss: 1.2772] [Valid Acc: 0.5600]\n",
      "[Epoch 120/200] [Train Loss: 0.5894] [Train Acc: 0.7762] [Valid Loss: 1.3515] [Valid Acc: 0.5000]\n",
      "[Epoch 121/200] [Train Loss: 0.5448] [Train Acc: 0.8102] [Valid Loss: 1.3395] [Valid Acc: 0.5267]\n",
      "[Epoch 122/200] [Train Loss: 0.6040] [Train Acc: 0.7705] [Valid Loss: 1.2611] [Valid Acc: 0.5800]\n",
      "[Epoch 123/200] [Train Loss: 0.6041] [Train Acc: 0.7847] [Valid Loss: 1.2939] [Valid Acc: 0.5733]\n",
      "[Epoch 124/200] [Train Loss: 0.6656] [Train Acc: 0.7535] [Valid Loss: 1.3420] [Valid Acc: 0.5533]\n",
      "[Epoch 125/200] [Train Loss: 0.6125] [Train Acc: 0.7535] [Valid Loss: 1.4147] [Valid Acc: 0.5067]\n",
      "[Epoch 126/200] [Train Loss: 0.5750] [Train Acc: 0.7762] [Valid Loss: 1.2873] [Valid Acc: 0.5667]\n",
      "[Epoch 127/200] [Train Loss: 0.5589] [Train Acc: 0.8159] [Valid Loss: 1.3569] [Valid Acc: 0.5333]\n",
      "[Epoch 128/200] [Train Loss: 0.6611] [Train Acc: 0.7479] [Valid Loss: 1.3570] [Valid Acc: 0.5400]\n",
      "[Epoch 129/200] [Train Loss: 0.5969] [Train Acc: 0.7649] [Valid Loss: 1.3330] [Valid Acc: 0.5133]\n",
      "[Epoch 130/200] [Train Loss: 0.6546] [Train Acc: 0.7592] [Valid Loss: 1.2702] [Valid Acc: 0.5667]\n",
      "[Epoch 131/200] [Train Loss: 0.6610] [Train Acc: 0.7620] [Valid Loss: 1.3108] [Valid Acc: 0.5600]\n",
      "[Epoch 132/200] [Train Loss: 0.7207] [Train Acc: 0.7309] [Valid Loss: 1.3901] [Valid Acc: 0.5200]\n",
      "[Epoch 133/200] [Train Loss: 0.6122] [Train Acc: 0.7649] [Valid Loss: 1.3306] [Valid Acc: 0.5667]\n",
      "[Epoch 134/200] [Train Loss: 0.6347] [Train Acc: 0.7649] [Valid Loss: 1.3490] [Valid Acc: 0.5133]\n",
      "[Epoch 135/200] [Train Loss: 0.6204] [Train Acc: 0.7649] [Valid Loss: 1.3341] [Valid Acc: 0.5600]\n",
      "[Epoch 136/200] [Train Loss: 0.6150] [Train Acc: 0.7932] [Valid Loss: 1.3479] [Valid Acc: 0.5200]\n",
      "[Epoch 137/200] [Train Loss: 0.6211] [Train Acc: 0.7790] [Valid Loss: 1.2720] [Valid Acc: 0.5467]\n",
      "[Epoch 138/200] [Train Loss: 0.5903] [Train Acc: 0.7819] [Valid Loss: 1.2948] [Valid Acc: 0.5400]\n",
      "[Epoch 139/200] [Train Loss: 0.6054] [Train Acc: 0.7762] [Valid Loss: 1.3406] [Valid Acc: 0.5400]\n",
      "[Epoch 140/200] [Train Loss: 0.5892] [Train Acc: 0.8017] [Valid Loss: 1.3569] [Valid Acc: 0.5467]\n",
      "[Epoch 141/200] [Train Loss: 0.6762] [Train Acc: 0.7309] [Valid Loss: 1.3763] [Valid Acc: 0.5267]\n",
      "[Epoch 142/200] [Train Loss: 0.5946] [Train Acc: 0.7790] [Valid Loss: 1.3010] [Valid Acc: 0.5600]\n",
      "[Epoch 143/200] [Train Loss: 0.5426] [Train Acc: 0.7932] [Valid Loss: 1.3114] [Valid Acc: 0.5667]\n",
      "[Epoch 144/200] [Train Loss: 0.6003] [Train Acc: 0.7705] [Valid Loss: 1.3123] [Valid Acc: 0.5333]\n",
      "[Epoch 145/200] [Train Loss: 0.7130] [Train Acc: 0.7422] [Valid Loss: 1.2724] [Valid Acc: 0.5667]\n",
      "[Epoch 146/200] [Train Loss: 0.6234] [Train Acc: 0.7960] [Valid Loss: 1.4362] [Valid Acc: 0.4867]\n",
      "[Epoch 147/200] [Train Loss: 0.5577] [Train Acc: 0.8074] [Valid Loss: 1.3495] [Valid Acc: 0.5133]\n",
      "[Epoch 148/200] [Train Loss: 0.5686] [Train Acc: 0.8102] [Valid Loss: 1.3502] [Valid Acc: 0.5667]\n",
      "[Epoch 149/200] [Train Loss: 0.6559] [Train Acc: 0.7847] [Valid Loss: 1.3731] [Valid Acc: 0.5400]\n",
      "[Epoch 150/200] [Train Loss: 0.5409] [Train Acc: 0.8102] [Valid Loss: 1.2965] [Valid Acc: 0.5733]\n",
      "[Epoch 151/200] [Train Loss: 0.7209] [Train Acc: 0.7479] [Valid Loss: 1.3156] [Valid Acc: 0.5533]\n",
      "[Epoch 152/200] [Train Loss: 0.5914] [Train Acc: 0.7847] [Valid Loss: 1.2518] [Valid Acc: 0.5933]\n",
      "[Epoch 153/200] [Train Loss: 0.6224] [Train Acc: 0.7734] [Valid Loss: 1.3195] [Valid Acc: 0.5400]\n",
      "[Epoch 154/200] [Train Loss: 0.6213] [Train Acc: 0.7819] [Valid Loss: 1.3026] [Valid Acc: 0.5667]\n",
      "[Epoch 155/200] [Train Loss: 0.5652] [Train Acc: 0.7989] [Valid Loss: 1.3252] [Valid Acc: 0.5267]\n",
      "[Epoch 156/200] [Train Loss: 0.5407] [Train Acc: 0.8300] [Valid Loss: 1.3308] [Valid Acc: 0.5333]\n",
      "[Epoch 157/200] [Train Loss: 0.5852] [Train Acc: 0.7734] [Valid Loss: 1.2834] [Valid Acc: 0.5667]\n",
      "[Epoch 158/200] [Train Loss: 0.5497] [Train Acc: 0.7960] [Valid Loss: 1.2544] [Valid Acc: 0.5600]\n",
      "[Epoch 159/200] [Train Loss: 0.6328] [Train Acc: 0.7734] [Valid Loss: 1.3080] [Valid Acc: 0.5467]\n",
      "[Epoch 160/200] [Train Loss: 0.6156] [Train Acc: 0.7932] [Valid Loss: 1.3171] [Valid Acc: 0.5600]\n",
      "[Epoch 161/200] [Train Loss: 0.5717] [Train Acc: 0.7875] [Valid Loss: 1.3071] [Valid Acc: 0.5533]\n",
      "[Epoch 162/200] [Train Loss: 0.6289] [Train Acc: 0.7762] [Valid Loss: 1.2922] [Valid Acc: 0.5800]\n",
      "[Epoch 163/200] [Train Loss: 0.6175] [Train Acc: 0.7507] [Valid Loss: 1.3359] [Valid Acc: 0.5267]\n",
      "[Epoch 164/200] [Train Loss: 0.6216] [Train Acc: 0.7762] [Valid Loss: 1.3017] [Valid Acc: 0.5533]\n",
      "[Epoch 165/200] [Train Loss: 0.6278] [Train Acc: 0.7989] [Valid Loss: 1.3531] [Valid Acc: 0.5200]\n",
      "[Epoch 166/200] [Train Loss: 0.6473] [Train Acc: 0.7507] [Valid Loss: 1.3406] [Valid Acc: 0.5400]\n",
      "[Epoch 167/200] [Train Loss: 0.6175] [Train Acc: 0.7649] [Valid Loss: 1.2752] [Valid Acc: 0.5733]\n",
      "[Epoch 168/200] [Train Loss: 0.6057] [Train Acc: 0.7904] [Valid Loss: 1.3189] [Valid Acc: 0.5667]\n",
      "[Epoch 169/200] [Train Loss: 0.5515] [Train Acc: 0.7960] [Valid Loss: 1.2801] [Valid Acc: 0.5667]\n",
      "[Epoch 170/200] [Train Loss: 0.6011] [Train Acc: 0.7875] [Valid Loss: 1.2864] [Valid Acc: 0.5600]\n",
      "[Epoch 171/200] [Train Loss: 0.6415] [Train Acc: 0.7762] [Valid Loss: 1.3645] [Valid Acc: 0.5200]\n",
      "[Epoch 172/200] [Train Loss: 0.5799] [Train Acc: 0.7847] [Valid Loss: 1.3216] [Valid Acc: 0.5600]\n",
      "[Epoch 173/200] [Train Loss: 0.6073] [Train Acc: 0.7705] [Valid Loss: 1.3743] [Valid Acc: 0.5000]\n",
      "[Epoch 174/200] [Train Loss: 0.6618] [Train Acc: 0.7620] [Valid Loss: 1.3273] [Valid Acc: 0.5533]\n",
      "[Epoch 175/200] [Train Loss: 0.5675] [Train Acc: 0.8130] [Valid Loss: 1.2778] [Valid Acc: 0.5733]\n",
      "[Epoch 176/200] [Train Loss: 0.6297] [Train Acc: 0.7762] [Valid Loss: 1.3022] [Valid Acc: 0.5467]\n",
      "[Epoch 177/200] [Train Loss: 0.5696] [Train Acc: 0.7904] [Valid Loss: 1.2923] [Valid Acc: 0.5733]\n",
      "[Epoch 178/200] [Train Loss: 0.6817] [Train Acc: 0.7479] [Valid Loss: 1.3454] [Valid Acc: 0.5133]\n",
      "[Epoch 179/200] [Train Loss: 0.6159] [Train Acc: 0.7960] [Valid Loss: 1.3045] [Valid Acc: 0.5333]\n",
      "[Epoch 180/200] [Train Loss: 0.6694] [Train Acc: 0.7479] [Valid Loss: 1.2745] [Valid Acc: 0.5800]\n",
      "[Epoch 181/200] [Train Loss: 0.6659] [Train Acc: 0.7649] [Valid Loss: 1.3354] [Valid Acc: 0.5667]\n",
      "[Epoch 182/200] [Train Loss: 0.5413] [Train Acc: 0.8187] [Valid Loss: 1.3190] [Valid Acc: 0.5333]\n",
      "[Epoch 183/200] [Train Loss: 0.5965] [Train Acc: 0.7762] [Valid Loss: 1.2825] [Valid Acc: 0.5533]\n",
      "[Epoch 184/200] [Train Loss: 0.6404] [Train Acc: 0.8045] [Valid Loss: 1.3275] [Valid Acc: 0.5533]\n",
      "[Epoch 185/200] [Train Loss: 0.6365] [Train Acc: 0.7734] [Valid Loss: 1.3926] [Valid Acc: 0.4933]\n",
      "[Epoch 186/200] [Train Loss: 0.5815] [Train Acc: 0.7790] [Valid Loss: 1.3134] [Valid Acc: 0.5200]\n",
      "[Epoch 187/200] [Train Loss: 0.5915] [Train Acc: 0.7677] [Valid Loss: 1.2870] [Valid Acc: 0.5667]\n",
      "[Epoch 188/200] [Train Loss: 0.6041] [Train Acc: 0.7904] [Valid Loss: 1.3201] [Valid Acc: 0.5733]\n",
      "[Epoch 189/200] [Train Loss: 0.6141] [Train Acc: 0.7819] [Valid Loss: 1.2615] [Valid Acc: 0.6067]\n",
      "[Epoch 190/200] [Train Loss: 0.6894] [Train Acc: 0.7450] [Valid Loss: 1.2963] [Valid Acc: 0.5933]\n",
      "[Epoch 191/200] [Train Loss: 0.6531] [Train Acc: 0.7649] [Valid Loss: 1.3638] [Valid Acc: 0.5667]\n",
      "[Epoch 192/200] [Train Loss: 0.5908] [Train Acc: 0.7762] [Valid Loss: 1.2977] [Valid Acc: 0.5400]\n",
      "[Epoch 193/200] [Train Loss: 0.6632] [Train Acc: 0.7734] [Valid Loss: 1.3093] [Valid Acc: 0.5733]\n",
      "[Epoch 194/200] [Train Loss: 0.6622] [Train Acc: 0.7762] [Valid Loss: 1.2928] [Valid Acc: 0.5733]\n",
      "[Epoch 195/200] [Train Loss: 0.5553] [Train Acc: 0.7960] [Valid Loss: 1.3328] [Valid Acc: 0.5600]\n",
      "[Epoch 196/200] [Train Loss: 0.5350] [Train Acc: 0.8017] [Valid Loss: 1.3025] [Valid Acc: 0.5533]\n",
      "[Epoch 197/200] [Train Loss: 0.5917] [Train Acc: 0.7904] [Valid Loss: 1.3251] [Valid Acc: 0.6000]\n",
      "[Epoch 198/200] [Train Loss: 0.6058] [Train Acc: 0.8074] [Valid Loss: 1.2797] [Valid Acc: 0.5667]\n",
      "[Epoch 199/200] [Train Loss: 0.5868] [Train Acc: 0.7960] [Valid Loss: 1.2594] [Valid Acc: 0.5600]\n",
      "[Epoch 200/200] [Train Loss: 0.5970] [Train Acc: 0.7649] [Valid Loss: 1.3115] [Valid Acc: 0.5467]\n",
      "Training Finished\n",
      "Test Accuracy: 62.56%\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
